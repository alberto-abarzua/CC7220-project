{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-procesing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choice\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from shutil import rmtree\n",
    "import pandas as pd\n",
    "import json\n",
    "import dateutil.parser\n",
    "import os\n",
    "from urllib.parse import quote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Datos de kaggle\n",
    "RAW_DATA = Path(\"raw_dataset\").absolute()\n",
    "\n",
    "#Output de datos (datos limpios)\n",
    "\n",
    "CLEAN_DATA = Path(\"clean_dataset\").absolute()\n",
    "\n",
    "if  CLEAN_DATA.exists():\n",
    "    rmtree(CLEAN_DATA)\n",
    "    os.mkdir(CLEAN_DATA)\n",
    "else:\n",
    "    os.mkdir(CLEAN_DATA)\n",
    "\n",
    "FRAC = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abriendo archivos del dataset-->\n",
      "\tPais: US  10/10 \n",
      "Datos Cargados!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "countries = [\"CA\",\"DE\",\"FR\",\"GB\",\"JP\",\"KR\",\"IN\",\"MX\",\"RU\",\"US\"] #Lista de paÃ­ses.\n",
    "videos = {} #Lista con los dataframes de archivos csv\n",
    "categories = {} # Lista con los diccionarios de los archivos json.\n",
    "print(\"Abriendo archivos del dataset-->\")\n",
    "for i,country in enumerate(countries):\n",
    "    print(f\"\\tPais: {country}  {i+1}/{len(countries)} \",end = \"\\r\")\n",
    "    file_csv = RAW_DATA.joinpath(f\"{country}videos.csv\")\n",
    "    videos[country] = pd.read_csv(file_csv,encoding=\"ISO-8859-1\",lineterminator=\"\\n\")\n",
    "    videos[country].columns = [x.strip() for x in videos[country].columns]\n",
    "\n",
    "\n",
    "    with open(RAW_DATA.joinpath(f\"{country}_category_id.json\")) as file:\n",
    "        items = json.load(file)[\"items\"]\n",
    "        temp = {int(x[\"id\"]): x for x in items} #La llave de cada categoria es su id.\n",
    "        val = defaultdict(lambda: \"NULL\")\n",
    "        val[\"snippet\"] = defaultdict(lambda:\"NULL\")\n",
    "        val[\"snippet\"][\"title\"] = 'No categoria'\n",
    "        categories[country] = defaultdict(lambda : val,temp)\n",
    "print(\"\\nDatos Cargados!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de filas con algun nulo (sin contar descripcion) en el DF de \n",
      "\tPais --> CA: 0\n",
      "\tPais --> DE: 0\n",
      "\tPais --> FR: 0\n",
      "\tPais --> GB: 0\n",
      "\tPais --> JP: 0\n",
      "\tPais --> KR: 0\n",
      "\tPais --> IN: 0\n",
      "\tPais --> MX: 0\n",
      "\tPais --> RU: 0\n",
      "\tPais --> US: 0\n"
     ]
    }
   ],
   "source": [
    "# veamos el numero de nulos sin contar la descripcion de cada DF\n",
    "print(\"Numero de filas con algun nulo (sin contar descripcion) en el DF de \")\n",
    "for key,df_clean in videos.items():\n",
    "    df = df_clean.copy().drop([\"description\"],axis = 1)\n",
    "    df1 = df[df.isna().any(axis=1)]\n",
    "    print(f\"\\tPais --> {key}: {len(df1)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = '%Y-%m-%dT%H:%M:%S'\n",
    "\n",
    "def get_category_name(series,key):\n",
    "    return series.apply(lambda x: categories[key][x][\"snippet\"][\"title\"])\n",
    "\n",
    "def get_publish_timestamp(series):\n",
    "    return series.apply(lambda x: dateutil.parser.isoparse(x).strftime(f))\n",
    "\n",
    "def get_trending_timestamp(series):\n",
    "    return series.apply(lambda x: datetime.strptime(x,\"%y.%d.%m\").strftime(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key,df in videos.items():\n",
    "    df[\"category\"] = get_category_name(df[\"category_id\"],key) # Agregamos el nombre de la categoria\n",
    "    # Parseamos las fechas para llegar y comparar como timestamps\n",
    "    df[\"publish_timestamp\"] = get_publish_timestamp(df[\"publish_time\"]) \n",
    "    df[\"trending_timestamp\"] = get_trending_timestamp(df[\"trending_date\"]) \n",
    "    df.drop([\"video_id\",\"category_id\",\"thumbnail_link\"],axis =1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Escribiendo nuevo dataset-->\n",
      "Escribiendo USvideos.csv   10/10\n",
      " Dataset listo!\n"
     ]
    }
   ],
   "source": [
    "print(\"Escribiendo nuevo dataset-->\")\n",
    "df_all = pd.DataFrame(columns = [\"country\"]+ list(videos[\"CA\"].columns))\n",
    "for i,(key,df) in enumerate(videos.items()):\n",
    "    df[\"country\"] = key\n",
    "    print(f\"Escribiendo {key}videos.csv   {i+1}/{len(videos.items())}\",end = \"\\r\")\n",
    "    # get 10% sample of df\n",
    "    # remove rows with no tags\n",
    "    df = df[df[\"tags\"] != \"[none]\"]\n",
    "    df = df.sample(frac=FRAC)\n",
    "    df_all = pd.concat([df_all,df],ignore_index = True)\n",
    "# Add numeric id to each row called video_id\n",
    "df_all[\"video_id\"] = df_all.index\n",
    "\n",
    "print(\"\\n Dataset listo!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>trending_date</th>\n",
       "      <th>title</th>\n",
       "      <th>channel_title</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>tags</th>\n",
       "      <th>views</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>comments_disabled</th>\n",
       "      <th>ratings_disabled</th>\n",
       "      <th>video_error_or_removed</th>\n",
       "      <th>description</th>\n",
       "      <th>category</th>\n",
       "      <th>publish_timestamp</th>\n",
       "      <th>trending_timestamp</th>\n",
       "      <th>video_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CA</td>\n",
       "      <td>18.07.06</td>\n",
       "      <td>Can you solve the penniless pilgrim riddle? - ...</td>\n",
       "      <td>TED-Ed</td>\n",
       "      <td>2018-06-04T15:03:15.000Z</td>\n",
       "      <td>TED|\"TED-Ed\"|\"TED Ed\"|\"Teded\"|\"Ted Education\"|...</td>\n",
       "      <td>494015</td>\n",
       "      <td>17673</td>\n",
       "      <td>367</td>\n",
       "      <td>1240</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>If you enjoy our riddles, we highly recommend ...</td>\n",
       "      <td>Education</td>\n",
       "      <td>2018-06-04T15:03:15</td>\n",
       "      <td>2018-06-07T00:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CA</td>\n",
       "      <td>18.26.01</td>\n",
       "      <td>FLOWER BOY: a conversation</td>\n",
       "      <td>Tyler, The Creator</td>\n",
       "      <td>2018-01-22T15:33:36.000Z</td>\n",
       "      <td>tyler the creator|\"jerrod carmichael\"|\"scum fu...</td>\n",
       "      <td>911172</td>\n",
       "      <td>62082</td>\n",
       "      <td>408</td>\n",
       "      <td>4632</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Jerrod Carmichael / Tyler Okonma\\n\\nDirected B...</td>\n",
       "      <td>Education</td>\n",
       "      <td>2018-01-22T15:33:36</td>\n",
       "      <td>2018-01-26T00:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CA</td>\n",
       "      <td>18.04.02</td>\n",
       "      <td>Comment Awards v55</td>\n",
       "      <td>Comment Awards</td>\n",
       "      <td>2018-02-03T23:18:41.000Z</td>\n",
       "      <td>comment awards|\"comment\"|\"awards\"|\"dank memes ...</td>\n",
       "      <td>322991</td>\n",
       "      <td>10093</td>\n",
       "      <td>279</td>\n",
       "      <td>2394</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Welcome to Comment Awards, your #1 source for ...</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>2018-02-03T23:18:41</td>\n",
       "      <td>2018-02-04T00:00:00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CA</td>\n",
       "      <td>18.21.05</td>\n",
       "      <td>Heartwarming Moment Doria Holds Hands with Pri...</td>\n",
       "      <td>MIU MIU</td>\n",
       "      <td>2018-05-20T10:27:20.000Z</td>\n",
       "      <td>Doria|\"MEGHAN MARKLE'S MOTHER\"|\"meghan's mothe...</td>\n",
       "      <td>606359</td>\n",
       "      <td>2774</td>\n",
       "      <td>408</td>\n",
       "      <td>389</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Heartwarming Moment Doria Holds Hands with Pri...</td>\n",
       "      <td>People &amp; Blogs</td>\n",
       "      <td>2018-05-20T10:27:20</td>\n",
       "      <td>2018-05-21T00:00:00</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CA</td>\n",
       "      <td>18.08.05</td>\n",
       "      <td>Jada Pinkett Smith's Mom Had Jada When She Was...</td>\n",
       "      <td>The Real Daytime</td>\n",
       "      <td>2018-05-07T17:49:39.000Z</td>\n",
       "      <td>the real|\"daytime\"|\"talk show\"|\"women\"|\"tamera...</td>\n",
       "      <td>69361</td>\n",
       "      <td>1204</td>\n",
       "      <td>15</td>\n",
       "      <td>76</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>2018-05-07T17:49:39</td>\n",
       "      <td>2018-05-08T00:00:00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country trending_date                                              title  \\\n",
       "0      CA      18.07.06  Can you solve the penniless pilgrim riddle? - ...   \n",
       "1      CA      18.26.01                         FLOWER BOY: a conversation   \n",
       "2      CA      18.04.02                                 Comment Awards v55   \n",
       "3      CA      18.21.05  Heartwarming Moment Doria Holds Hands with Pri...   \n",
       "4      CA      18.08.05  Jada Pinkett Smith's Mom Had Jada When She Was...   \n",
       "\n",
       "        channel_title              publish_time  \\\n",
       "0              TED-Ed  2018-06-04T15:03:15.000Z   \n",
       "1  Tyler, The Creator  2018-01-22T15:33:36.000Z   \n",
       "2      Comment Awards  2018-02-03T23:18:41.000Z   \n",
       "3             MIU MIU  2018-05-20T10:27:20.000Z   \n",
       "4    The Real Daytime  2018-05-07T17:49:39.000Z   \n",
       "\n",
       "                                                tags   views  likes dislikes  \\\n",
       "0  TED|\"TED-Ed\"|\"TED Ed\"|\"Teded\"|\"Ted Education\"|...  494015  17673      367   \n",
       "1  tyler the creator|\"jerrod carmichael\"|\"scum fu...  911172  62082      408   \n",
       "2  comment awards|\"comment\"|\"awards\"|\"dank memes ...  322991  10093      279   \n",
       "3  Doria|\"MEGHAN MARKLE'S MOTHER\"|\"meghan's mothe...  606359   2774      408   \n",
       "4  the real|\"daytime\"|\"talk show\"|\"women\"|\"tamera...   69361   1204       15   \n",
       "\n",
       "  comment_count comments_disabled ratings_disabled video_error_or_removed  \\\n",
       "0          1240             False            False                  False   \n",
       "1          4632             False            False                  False   \n",
       "2          2394             False            False                  False   \n",
       "3           389             False            False                  False   \n",
       "4            76             False            False                  False   \n",
       "\n",
       "                                         description        category  \\\n",
       "0  If you enjoy our riddles, we highly recommend ...       Education   \n",
       "1  Jerrod Carmichael / Tyler Okonma\\n\\nDirected B...       Education   \n",
       "2  Welcome to Comment Awards, your #1 source for ...          Comedy   \n",
       "3  Heartwarming Moment Doria Holds Hands with Pri...  People & Blogs   \n",
       "4                                                NaN   Entertainment   \n",
       "\n",
       "     publish_timestamp   trending_timestamp  video_id  \n",
       "0  2018-06-04T15:03:15  2018-06-07T00:00:00         0  \n",
       "1  2018-01-22T15:33:36  2018-01-26T00:00:00         1  \n",
       "2  2018-02-03T23:18:41  2018-02-04T00:00:00         2  \n",
       "3  2018-05-20T10:27:20  2018-05-21T00:00:00         3  \n",
       "4  2018-05-07T17:49:39  2018-05-08T00:00:00         4  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Tables for tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------BEFORE------------\n",
      "\n",
      "Number of unique tags : 151086\n",
      "Total number of tags: 320725\n",
      "\n",
      "------------AFTER------------\n",
      "\n",
      "Number of unique tags : 67\n",
      "Total number of tags. 11604\n",
      "Rows without tags 11507\n"
     ]
    }
   ],
   "source": [
    "tags_series = df_all[\"tags\"].apply(lambda x: x.split(\"|\"))\n",
    "tags_series = tags_series.apply(lambda x: [y.strip() for y in x])\n",
    "tags = [item for sublist in tags_series for item in sublist] # Lista con todas las tags.\n",
    "new_tags = []\n",
    "for tag in tags:\n",
    "    # remove \" from tags\n",
    "    tag = tag.replace('\"',\"\")\n",
    "    # Replace spaces with _\n",
    "    tag = tag.replace(\" \",\"_\")\n",
    "    tag = quote(tag,safe='/:?=&')\n",
    "    new_tags.append(tag)\n",
    "\n",
    "tags = new_tags\n",
    "\n",
    "\n",
    "# Count frequency of each tag\n",
    "freq_dict = {}\n",
    "for tag in tags:\n",
    "    if tag in freq_dict:\n",
    "        freq_dict[tag] += 1\n",
    "    else:\n",
    "        freq_dict[tag] = 1\n",
    "\n",
    "# Remove tags that appear less than 100 times\n",
    "\n",
    "thresh = 100\n",
    "\n",
    "freq_dict = {key:value for key,value in freq_dict.items() if value >= thresh}\n",
    "tag_set = freq_dict.keys()\n",
    "\n",
    "\n",
    "# Remove from every elemnt in tag series values that are not in final_set\n",
    "def remove_tags(x):\n",
    "    res = []\n",
    "    for elem in x:\n",
    "        elem  = elem.replace('\"',\"\")\n",
    "        # Replace spaces with _\n",
    "        elem = elem.replace(\" \",\"_\")\n",
    "        elem = quote(elem,safe='/:?=&')\n",
    "        if elem in tag_set:\n",
    "            res.append(elem)\n",
    "\n",
    "    return res\n",
    "\n",
    "tags_series = tags_series.apply(remove_tags)\n",
    "\n",
    "\n",
    "\n",
    "# print info\n",
    "\n",
    "print(\"\\n------------BEFORE------------\\n\")\n",
    "print(f\"Number of unique tags : {len(set(new_tags))}\")\n",
    "print(f\"Total number of tags: {len(new_tags)}\")\n",
    "print(\"\\n------------AFTER------------\\n\")\n",
    "\n",
    "print(f\"Number of unique tags : {len(tag_set)}\")\n",
    "print(\"Total number of tags.\",sum(freq_dict.values()))\n",
    "print(\"Rows without tags {}\".format(len(tags_series[tags_series.apply(lambda x: len(x) == 0)])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# create enw dataframe with 2 columns video_id and tag_id\n",
    "video_tag_df = pd.DataFrame(columns = [\"video_id\",\"tag_name\"],index = range(sum(freq_dict.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for elem in enumerate(tags_series):\n",
    "    L = elem[1]\n",
    "    for tag in L:\n",
    "        video_tag_df.loc[counter] = [elem[0],tag]\n",
    "        counter += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_all.drop([\"tags\",\"description\"],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>tag_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>interview</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>funny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>talk_show</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>youtube</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11599</th>\n",
       "      <td>16906</td>\n",
       "      <td>Music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11600</th>\n",
       "      <td>16906</td>\n",
       "      <td>Records</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11601</th>\n",
       "      <td>16910</td>\n",
       "      <td>Trailer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11602</th>\n",
       "      <td>16910</td>\n",
       "      <td>television</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11603</th>\n",
       "      <td>16910</td>\n",
       "      <td>drama</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11604 rows Ã 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id    tag_name\n",
       "0            1   interview\n",
       "1            2       funny\n",
       "2            4   talk_show\n",
       "3            7     youtube\n",
       "4            8    politics\n",
       "...        ...         ...\n",
       "11599    16906       Music\n",
       "11600    16906     Records\n",
       "11601    16910     Trailer\n",
       "11602    16910  television\n",
       "11603    16910       drama\n",
       "\n",
       "[11604 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_tag_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values of category\n",
      "['Education' 'Comedy' 'People_&_Blogs' 'Entertainment' 'Sports'\n",
      " 'News_&_Politics' 'Autos_&_Vehicles' 'Music' 'Gaming' 'Movies'\n",
      " 'Science_&_Technology' 'Howto_&_Style' 'Film_&_Animation'\n",
      " 'Pets_&_Animals' 'Shows' 'No_categoria' 'Travel_&_Events'\n",
      " 'Nonprofits_&_Activism']\n"
     ]
    }
   ],
   "source": [
    "# show uniqute values of category\n",
    "print(\"Unique values of category\")\n",
    "\n",
    "\n",
    "\n",
    "# result: http://www.oschina.net/search?scope=bbs&q=C%E8%AF%AD%E8%A8%80\n",
    "quote('http://www.oschina.net/search?scope=bbs&q=Cè¯­è¨',safe='/:?=&')\n",
    "# replace \" \" with \"_\"\n",
    "df_all[\"category\"] = df_all[\"category\"].apply(lambda x: x.replace(\" \",\"_\"))\n",
    "# remove control caracters from channel_tittle\n",
    "df_all[\"channel_title\"] = df_all[\"channel_title\"].apply(lambda x: x.replace(\" \",\"_\"))\n",
    "df_all[\"channel_title\"] = df_all[\"channel_title\"].apply(lambda x: quote(x,safe='/:?=&'))\n",
    "\n",
    "print(df_all[\"category\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataframes to csv\n",
    "df_all.to_csv(CLEAN_DATA /\"videos.csv\",index = False)\n",
    "video_tag_df.to_csv(CLEAN_DATA /\"video_tags.csv\",index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('mineria_datos')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0d53d113c62f660b6f104f70cfe7db2841890f6f762fbaa5e6c544d2e40226b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
