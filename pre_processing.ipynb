{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-procesing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 988,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choice\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from shutil import rmtree\n",
    "import pandas as pd\n",
    "import json\n",
    "import dateutil.parser\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 989,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Datos de kaggle\n",
    "RAW_DATA = Path(\"raw_dataset\").absolute()\n",
    "\n",
    "#Output de datos (datos limpios)\n",
    "\n",
    "CLEAN_DATA = Path(\"clean_dataset\").absolute()\n",
    "\n",
    "if  CLEAN_DATA.exists():\n",
    "    rmtree(CLEAN_DATA)\n",
    "    os.mkdir(CLEAN_DATA)\n",
    "else:\n",
    "    os.mkdir(CLEAN_DATA)\n",
    "\n",
    "FRAC = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 990,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abriendo archivos del dataset-->\n",
      "\tPais: US  3/3 \n",
      "Datos Cargados!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "countries = [\"CA\",\"GB\",\"US\"] #Lista de paiess.\n",
    "videos = {} #Lista con los dataframes de archivos csv\n",
    "categories = {} # Lista con los diccionarios de los archivos json.\n",
    "print(\"Abriendo archivos del dataset-->\")\n",
    "for i,country in enumerate(countries):\n",
    "    print(f\"\\tPais: {country}  {i+1}/{len(countries)} \",end = \"\\r\")\n",
    "    file_csv = RAW_DATA.joinpath(f\"{country}videos.csv\")\n",
    "    videos[country] = pd.read_csv(file_csv,encoding=\"ISO-8859-1\",lineterminator=\"\\n\")\n",
    "    videos[country].columns = [x.strip() for x in videos[country].columns]\n",
    "\n",
    "\n",
    "    with open(RAW_DATA.joinpath(f\"{country}_category_id.json\")) as file:\n",
    "        items = json.load(file)[\"items\"]\n",
    "        temp = {int(x[\"id\"]): x for x in items} #La llave de cada categoria es su id.\n",
    "        val = defaultdict(lambda: \"NULL\")\n",
    "        val[\"snippet\"] = defaultdict(lambda:\"NULL\")\n",
    "        val[\"snippet\"][\"title\"] = 'No categoria'\n",
    "        categories[country] = defaultdict(lambda : val,temp)\n",
    "print(\"\\nDatos Cargados!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 991,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de filas con algun nulo (sin contar descripcion) en el DF de \n",
      "\tPais --> CA: 0\n",
      "\tPais --> GB: 0\n",
      "\tPais --> US: 0\n"
     ]
    }
   ],
   "source": [
    "# veamos el numero de nulos sin contar la descripcion de cada DF\n",
    "print(\"Numero de filas con algun nulo (sin contar descripcion) en el DF de \")\n",
    "for key,df_clean in videos.items():\n",
    "    df = df_clean.copy().drop([\"description\"],axis = 1)\n",
    "    df1 = df[df.isna().any(axis=1)]\n",
    "    print(f\"\\tPais --> {key}: {len(df1)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 992,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = '%Y-%m-%dT%H:%M:%S'\n",
    "\n",
    "def get_category_name(series,key):\n",
    "    return series.apply(lambda x: categories[key][x][\"snippet\"][\"title\"])\n",
    "\n",
    "def get_publish_timestamp(series):\n",
    "    return series.apply(lambda x: dateutil.parser.isoparse(x).strftime(f))\n",
    "\n",
    "def get_trending_timestamp(series):\n",
    "    return series.apply(lambda x: datetime.strptime(x,\"%y.%d.%m\").strftime(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 993,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key,df in videos.items():\n",
    "    df[\"category\"] = get_category_name(df[\"category_id\"],key) # Agregamos el nombre de la categoria\n",
    "    # Parseamos las fechas para llegar y comparar como timestamps\n",
    "    df[\"publish_timestamp\"] = get_publish_timestamp(df[\"publish_time\"]) \n",
    "    df[\"trending_timestamp\"] = get_trending_timestamp(df[\"trending_date\"]) \n",
    "    df.drop([\"video_id\",\"category_id\",\"thumbnail_link\"],axis =1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 994,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Escribiendo nuevo dataset-->\n",
      "Escribiendo USvideos.csv   3/3\n",
      " Dataset listo!\n"
     ]
    }
   ],
   "source": [
    "print(\"Escribiendo nuevo dataset-->\")\n",
    "df_all = pd.DataFrame(columns = [\"country\"]+ list(videos[\"CA\"].columns))\n",
    "for i,(key,df) in enumerate(videos.items()):\n",
    "    df[\"country\"] = key\n",
    "    print(f\"Escribiendo {key}videos.csv   {i+1}/{len(videos.items())}\",end = \"\\r\")\n",
    "    # get 10% sample of df\n",
    "    # remove rows with no tags\n",
    "    df = df[df[\"tags\"] != \"[none]\"]\n",
    "    df = df.sample(frac=0.1)\n",
    "    df_all = pd.concat([df_all,df],ignore_index = True)\n",
    "# Add numeric id to each row called video_id\n",
    "df_all[\"video_id\"] = df_all.index\n",
    "\n",
    "print(\"\\n Dataset listo!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 995,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>trending_date</th>\n",
       "      <th>title</th>\n",
       "      <th>channel_title</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>tags</th>\n",
       "      <th>views</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>comments_disabled</th>\n",
       "      <th>ratings_disabled</th>\n",
       "      <th>video_error_or_removed</th>\n",
       "      <th>description</th>\n",
       "      <th>category</th>\n",
       "      <th>publish_timestamp</th>\n",
       "      <th>trending_timestamp</th>\n",
       "      <th>video_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CA</td>\n",
       "      <td>17.26.11</td>\n",
       "      <td>KUCKIAN COSMETICS LAUNCH!!!!</td>\n",
       "      <td>John Kuckian</td>\n",
       "      <td>2017-11-25T21:00:00.000Z</td>\n",
       "      <td>john|\"kuckian\"|\"british\"|\"youtuber\"|\"drama\"|\"j...</td>\n",
       "      <td>76935</td>\n",
       "      <td>5798</td>\n",
       "      <td>1267</td>\n",
       "      <td>3527</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>http://kuckian.co\\n\\nâ¶ï¸ Snapchat: JohnKuck...</td>\n",
       "      <td>News &amp; Politics</td>\n",
       "      <td>2017-11-25T21:00:00</td>\n",
       "      <td>2017-11-26T00:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CA</td>\n",
       "      <td>18.17.04</td>\n",
       "      <td>Michael Cohenâs Mystery Client Is Sean Hanni...</td>\n",
       "      <td>MSNBC</td>\n",
       "      <td>2018-04-17T01:15:26.000Z</td>\n",
       "      <td>Hardball|\"Hardball with Chris Matthews\"|\"Chris...</td>\n",
       "      <td>117294</td>\n",
       "      <td>1116</td>\n",
       "      <td>84</td>\n",
       "      <td>651</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Hannity never disclosed his relationship with ...</td>\n",
       "      <td>News &amp; Politics</td>\n",
       "      <td>2018-04-17T01:15:26</td>\n",
       "      <td>2018-04-17T00:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CA</td>\n",
       "      <td>18.14.02</td>\n",
       "      <td>what working tech support is REALLY like</td>\n",
       "      <td>Alex Meyers</td>\n",
       "      <td>2018-02-13T12:00:06.000Z</td>\n",
       "      <td>alex meyers|\"jaiden\"|\"animations\"|\"jaidenanima...</td>\n",
       "      <td>109050</td>\n",
       "      <td>10963</td>\n",
       "      <td>99</td>\n",
       "      <td>708</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>what working tech support is really like anima...</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>2018-02-13T12:00:06</td>\n",
       "      <td>2018-02-14T00:00:00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CA</td>\n",
       "      <td>18.11.05</td>\n",
       "      <td>GUESS THAT FOOD CHALLENGE! #2 | People Vs. Food</td>\n",
       "      <td>REACT</td>\n",
       "      <td>2018-05-10T19:00:02.000Z</td>\n",
       "      <td>Guess That Food|\"Cauliflower\"|\"Cabbage\"|\"GUESS...</td>\n",
       "      <td>149259</td>\n",
       "      <td>5164</td>\n",
       "      <td>95</td>\n",
       "      <td>834</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Staff try to Guess that food! Click to get Ama...</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>2018-05-10T19:00:02</td>\n",
       "      <td>2018-05-11T00:00:00</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CA</td>\n",
       "      <td>18.08.01</td>\n",
       "      <td>BuzzFeed Men Read Thirsty Comments</td>\n",
       "      <td>BuzzFeedVideo</td>\n",
       "      <td>2018-01-06T16:00:22.000Z</td>\n",
       "      <td>Buzzfeed|\"Hot\"|\"Sexy\"|\"Hot Guys\"|\"BuzzFeedVide...</td>\n",
       "      <td>931841</td>\n",
       "      <td>31652</td>\n",
       "      <td>479</td>\n",
       "      <td>2911</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Our audience isn't properly hydrated.\\n\\nCheck...</td>\n",
       "      <td>People &amp; Blogs</td>\n",
       "      <td>2018-01-06T16:00:22</td>\n",
       "      <td>2018-01-08T00:00:00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country trending_date                                              title  \\\n",
       "0      CA      17.26.11                       KUCKIAN COSMETICS LAUNCH!!!!   \n",
       "1      CA      18.17.04  Michael Cohenâs Mystery Client Is Sean Hanni...   \n",
       "2      CA      18.14.02           what working tech support is REALLY like   \n",
       "3      CA      18.11.05    GUESS THAT FOOD CHALLENGE! #2 | People Vs. Food   \n",
       "4      CA      18.08.01                 BuzzFeed Men Read Thirsty Comments   \n",
       "\n",
       "   channel_title              publish_time  \\\n",
       "0   John Kuckian  2017-11-25T21:00:00.000Z   \n",
       "1          MSNBC  2018-04-17T01:15:26.000Z   \n",
       "2    Alex Meyers  2018-02-13T12:00:06.000Z   \n",
       "3          REACT  2018-05-10T19:00:02.000Z   \n",
       "4  BuzzFeedVideo  2018-01-06T16:00:22.000Z   \n",
       "\n",
       "                                                tags   views  likes dislikes  \\\n",
       "0  john|\"kuckian\"|\"british\"|\"youtuber\"|\"drama\"|\"j...   76935   5798     1267   \n",
       "1  Hardball|\"Hardball with Chris Matthews\"|\"Chris...  117294   1116       84   \n",
       "2  alex meyers|\"jaiden\"|\"animations\"|\"jaidenanima...  109050  10963       99   \n",
       "3  Guess That Food|\"Cauliflower\"|\"Cabbage\"|\"GUESS...  149259   5164       95   \n",
       "4  Buzzfeed|\"Hot\"|\"Sexy\"|\"Hot Guys\"|\"BuzzFeedVide...  931841  31652      479   \n",
       "\n",
       "  comment_count comments_disabled ratings_disabled video_error_or_removed  \\\n",
       "0          3527             False            False                  False   \n",
       "1           651             False            False                  False   \n",
       "2           708             False            False                  False   \n",
       "3           834             False            False                  False   \n",
       "4          2911             False            False                  False   \n",
       "\n",
       "                                         description         category  \\\n",
       "0  http://kuckian.co\\n\\nâ¶ï¸ Snapchat: JohnKuck...  News & Politics   \n",
       "1  Hannity never disclosed his relationship with ...  News & Politics   \n",
       "2  what working tech support is really like anima...    Entertainment   \n",
       "3  Staff try to Guess that food! Click to get Ama...    Entertainment   \n",
       "4  Our audience isn't properly hydrated.\\n\\nCheck...   People & Blogs   \n",
       "\n",
       "     publish_timestamp   trending_timestamp  video_id  \n",
       "0  2017-11-25T21:00:00  2017-11-26T00:00:00         0  \n",
       "1  2018-04-17T01:15:26  2018-04-17T00:00:00         1  \n",
       "2  2018-02-13T12:00:06  2018-02-14T00:00:00         2  \n",
       "3  2018-05-10T19:00:02  2018-05-11T00:00:00         3  \n",
       "4  2018-01-06T16:00:22  2018-01-08T00:00:00         4  "
      ]
     },
     "execution_count": 995,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Tables for tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 996,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------BEFORE------------\n",
      "\n",
      "Number of unique tags : 239173\n",
      "Total number of tags: 648040\n",
      "\n",
      "------------AFTER------------\n",
      "\n",
      "Number of unique tags : 207\n",
      "Total number of tags. 42565\n",
      "Rows without tags 18052\n"
     ]
    }
   ],
   "source": [
    "tags_series = df_all[\"tags\"].apply(lambda x: x.split(\"|\"))\n",
    "tags_series = tags_series.apply(lambda x: [y.strip() for y in x])\n",
    "tags = [item for sublist in tags_series for item in sublist] # Lista con todas las tags.\n",
    "new_tags = []\n",
    "for tag in tags:\n",
    "    # remove \" from tags\n",
    "    tag = tag.replace('\"',\"\")\n",
    "    # Replace spaces with _\n",
    "    tag = tag.replace(\" \",\"_\")\n",
    "    new_tags.append(tag)\n",
    "\n",
    "tags = new_tags\n",
    "\n",
    "\n",
    "# Count frequency of each tag\n",
    "freq_dict = {}\n",
    "for tag in tags:\n",
    "    if tag in freq_dict:\n",
    "        freq_dict[tag] += 1\n",
    "    else:\n",
    "        freq_dict[tag] = 1\n",
    "\n",
    "# Remove tags that appear less than 100 times\n",
    "\n",
    "thresh = 100\n",
    "\n",
    "freq_dict = {key:value for key,value in freq_dict.items() if value >= thresh}\n",
    "tag_set = freq_dict.keys()\n",
    "\n",
    "\n",
    "# Remove from every elemnt in tag series values that are not in final_set\n",
    "def remove_tags(x):\n",
    "    res = []\n",
    "    for elem in x:\n",
    "        elem  = elem.replace('\"',\"\")\n",
    "        # Replace spaces with _\n",
    "        elem = elem.replace(\" \",\"_\")\n",
    "        if elem in tag_set:\n",
    "            res.append(elem)\n",
    "\n",
    "    return res\n",
    "\n",
    "tags_series = tags_series.apply(remove_tags)\n",
    "\n",
    "\n",
    "\n",
    "# print info\n",
    "\n",
    "print(\"\\n------------BEFORE------------\\n\")\n",
    "print(f\"Number of unique tags : {len(set(new_tags))}\")\n",
    "print(f\"Total number of tags: {len(new_tags)}\")\n",
    "print(\"\\n------------AFTER------------\\n\")\n",
    "\n",
    "print(f\"Number of unique tags : {len(tag_set)}\")\n",
    "print(\"Total number of tags.\",sum(freq_dict.values()))\n",
    "print(\"Rows without tags {}\".format(len(tags_series[tags_series.apply(lambda x: len(x) == 0)])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 997,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new dataframe with 2 columns tag_id and tag_name\n",
    "tag_df = pd.DataFrame(columns = [\"tag_id\",\"tag_name\"],index=  range(len(tag_set)))\n",
    "# create enw dataframe with 2 columns video_id and tag_id\n",
    "video_tag_df = pd.DataFrame(columns = [\"video_id\",\"tag_id\"],index = range(sum(freq_dict.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 998,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_dict = {}\n",
    "for i,elem in enumerate(tag_set):\n",
    "    tag_df.loc[i] = [i,elem]\n",
    "    id_dict[elem] = i\n",
    "counter = 0\n",
    "for elem in enumerate(tags_series):\n",
    "    L = elem[1]\n",
    "    for tag in L:\n",
    "        video_tag_df.loc[counter] = [elem[0],id_dict[tag]]\n",
    "        counter += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 999,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_all.drop([\"tags\",\"description\"],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1000,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>tag_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>youtuber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>fun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>beauty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Donald_Trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42560</th>\n",
       "      <td>33819</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42561</th>\n",
       "      <td>33820</td>\n",
       "      <td>Funny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42562</th>\n",
       "      <td>33822</td>\n",
       "      <td>BuzzFeed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42563</th>\n",
       "      <td>33824</td>\n",
       "      <td>review</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42564</th>\n",
       "      <td>33824</td>\n",
       "      <td>fashion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42565 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id      tag_name\n",
       "0            0      youtuber\n",
       "1            0         drama\n",
       "2            0           fun\n",
       "3            0        beauty\n",
       "4            1  Donald_Trump\n",
       "...        ...           ...\n",
       "42560    33819    technology\n",
       "42561    33820         Funny\n",
       "42562    33822      BuzzFeed\n",
       "42563    33824        review\n",
       "42564    33824       fashion\n",
       "\n",
       "[42565 rows x 2 columns]"
      ]
     },
     "execution_count": 1000,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_tag_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1001,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values of category\n",
      "['News_&_Politics' 'Entertainment' 'People_&_Blogs' 'Comedy'\n",
      " 'Travel_&_Events' 'Music' 'Sports' 'Education' 'Film_&_Animation'\n",
      " 'Howto_&_Style' 'Gaming' 'Science_&_Technology' 'Pets_&_Animals'\n",
      " 'Autos_&_Vehicles' 'Shows' 'No_categoria' 'Movies'\n",
      " 'Nonprofits_&_Activism']\n"
     ]
    }
   ],
   "source": [
    "# show uniqute values of category\n",
    "print(\"Unique values of category\")\n",
    "\n",
    "\n",
    "\n",
    "# result: http://www.oschina.net/search?scope=bbs&q=C%E8%AF%AD%E8%A8%80\n",
    "quote('http://www.oschina.net/search?scope=bbs&q=C语言',safe='/:?=&')\n",
    "# replace \" \" with \"_\"\n",
    "df_all[\"category\"] = df_all[\"category\"].apply(lambda x: x.replace(\" \",\"_\"))\n",
    "# remove control caracters from channel_tittle\n",
    "df_all[\"channel_title\"] = df_all[\"channel_title\"].apply(lambda x: x.replace(\" \",\"_\"))\n",
    "df_all[\"channel_title\"] = df_all[\"channel_title\"].apply(lambda x: quote(x,safe='/:?=&'))\n",
    "\n",
    "print(df_all[\"category\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1002,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataframes to csv\n",
    "df_all.to_csv(CLEAN_DATA /\"videos.csv\",index = False)\n",
    "tag_df.to_csv(CLEAN_DATA /\"tags.csv\",index = False)\n",
    "video_tag_df.to_csv(CLEAN_DATA /\"video_tags.csv\",index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('mineria_datos')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0d53d113c62f660b6f104f70cfe7db2841890f6f762fbaa5e6c544d2e40226b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
